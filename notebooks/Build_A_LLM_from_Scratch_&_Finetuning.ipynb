{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build a BPE tokenizer"
      ],
      "metadata": {
        "id": "LtDfGyYqsuYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import (\n",
        "    decoders,\n",
        "    models,\n",
        "    normalizers,\n",
        "    pre_tokenizers,\n",
        "    processors,\n",
        "    trainers,\n",
        "    Tokenizer,\n",
        ")\n"
      ],
      "metadata": {
        "id": "lKOFHx2-szPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_train_datafile = \"/content/drive/MyDrive/Build a LLM from scratch/dao_de_jing.txt\"\n",
        "with open(tokenizer_train_datafile, 'r', encoding='utf-8') as f:\n",
        "  dataset = [line.strip() for line in f.readlines() if line.strip()]"
      ],
      "metadata": {
        "id": "hSGfgCTx379r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_corpus():\n",
        "    for i in range(0, len(dataset)):\n",
        "        yield dataset[i]"
      ],
      "metadata": {
        "id": "WHx3fXF_uBRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(models.BPE())\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
        "\n",
        "trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=[\"<|endoftext|>\"])\n",
        "\n",
        "tokenizer.train([tokenizer_train_datafile], trainer=trainer)\n",
        "# tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
      ],
      "metadata": {
        "id": "O-YEqjYbtSxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tokenizer.encode(\"Le Tao éternel ne peut pas être nommé.\")\n",
        "print(encoding.tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvGulZ2M7wOg",
        "outputId": "81d68ddf-de8e-412f-e658-af0932d67355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Le', 'ĠTao', 'ĠÃ©ternel', 'Ġne', 'Ġpeut', 'Ġpas', 'ĠÃªtre', 'ĠnommÃ©', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)"
      ],
      "metadata": {
        "id": "_4usGaHI81aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Le Tao éternel ne peut pas être nommé.\"\n",
        "encoding = tokenizer.encode(sentence)\n",
        "start, end = encoding.offsets[4]\n",
        "sentence[start:end]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8fFYViJU87XH",
        "outputId": "234f8f1b-c5a6-4797-8a67-d60cdacd229e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' peut'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decoder = decoders.ByteLevel()"
      ],
      "metadata": {
        "id": "dW-kycxU9J2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(encoding.ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W0FwoJ3U9Nwu",
        "outputId": "8a485585-fd5c-4349-b78c-6e74cc04c149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Le Tao éternel ne peut pas être nommé.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "\n",
        "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
        "    tokenizer_object=tokenizer,\n",
        "    bos_token=\"<|endoftext|>\",\n",
        "    eos_token=\"<|endoftext|>\",\n",
        ")"
      ],
      "metadata": {
        "id": "hzSolPho9TUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2"
      ],
      "metadata": {
        "id": "7ChhGqe735Nm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQPRYCjAzAgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c0a3b5-9ab8-45e0-cc64-0216e6c2181e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters:  20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/Build a LLM from scratch/the-verdict.txt\", 'r', encoding='utf-8') as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "print(\"Total number of characters: \", len(raw_text))\n",
        "print(raw_text[:99])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello, world. This, is a test.\"\n",
        "\n",
        "tokens = re.split(r'(\\s)', string=text)\n",
        "\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGzjHRi-4z_q",
        "outputId": "52e4c283-98a6-45d3-c742-7a162b7a65d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = re.split(r'([,.|\\s])', string=text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvyQ8zF5GAh",
        "outputId": "570a48ad-49e9-47a1-944d-08723d4c3bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = [token.strip() for token in tokens if token.strip()]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLP-NSNU5z8f",
        "outputId": "cae31e89-bdfb-43a7-d9fc-8f73a5a593aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "tokens = re.split(r'([,.:!?;_]|\\s|--)', string=text)\n",
        "tokens = [token.strip() for token in tokens if token.strip()]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caoa6KWC6e4m",
        "outputId": "10036485-bfc9-4b17-dc58-69804dfcd4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.:!?;_\"()\\']|\\s|--)', string=raw_text)\n",
        "preprocessed = [token.strip() for token in preprocessed if token.strip()]\n",
        "\n",
        "print(len(preprocessed))\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB5dOkqc7s5d",
        "outputId": "2a1d5cc3-8331-4986-8c88-18255255dda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n",
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtJp4Gns86pO",
        "outputId": "d1ed634f-5f43-4304-83c4-eb4d2f082623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token: id for id, token in enumerate(all_words)}\n",
        "\n",
        "for i, item in enumerate(vocab.items()):\n",
        "  if i > 50:\n",
        "    break\n",
        "  print(item)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QJSGubY9Vot",
        "outputId": "3351a596-53ab-40fa-f515-272b0a60963b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.split(r'([,.:!?;_\"()\\']|\\s|--)', string=text)\n",
        "    preprocessed = [token.strip() for token in preprocessed if token.strip()]\n",
        "    ids = [self.str_to_int[tok] for tok in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_to_str[id] for id in ids])\n",
        "    text = re.sub(r'\\s+([,.?!\")\\'])', r'\\1', text)\n",
        "    text = re.sub(r'([(\"\\'])\\s+', r'\\1', text)\n",
        "    text = re.sub(r'.([(\"])', r'\\1 ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "otzPEr6n99sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "text = \"\"\"\"It's the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvp8ufSBCldP",
        "outputId": "5d2ee6e9-c6da-4327-b949-679b8701132a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8e1rthnC80Q",
        "outputId": "15298a5b-1a74-400e-df5c-c1702d5b5de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"It's the last he painted, you know\" Mrs. Gisburn said with pardonable pride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, do you like tea?\"\n",
        "#print(tokenizer.encode(text))"
      ],
      "metadata": {
        "id": "yaSlXtJ6FVNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Build a LLM from scratch/the-verdict.txt\", 'r', encoding='utf-8') as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "preprocessed = re.split(r'([,.:!?;_\"()\\']|\\s|--)', string=raw_text)\n",
        "preprocessed = [token.strip() for token in preprocessed if token.strip()]\n",
        "all_tokens = sorted(set(preprocessed))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "vocab = {token: id for id, token in enumerate(all_tokens)}\n"
      ],
      "metadata": {
        "id": "smGGHqryHvsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWN1Wg08J2kR",
        "outputId": "466f1bfa-de4e-4ada-9baa-d045e93ad7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2:\n",
        "\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.split(r'([,.:!?;_\"()\\']|\\s|--)', string=text)\n",
        "    preprocessed = [token.strip() for token in preprocessed if token.strip()]\n",
        "    preprocessed = [token if token in self.str_to_int else '<|unk|>' for token in preprocessed]\n",
        "    ids = [self.str_to_int[tok] for tok in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_to_str[id] for id in ids])\n",
        "    text = re.sub(r'\\s+([,.?!\")\\'])', r'\\1', text)\n",
        "    text = re.sub(r'([(\"\\'])\\s+', r'\\1', text)\n",
        "    text = re.sub(r'.([(\"])', r'\\1 ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "xjm70erSJU8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjHIxffjKxfH",
        "outputId": "9ee6e112-1f8d-41b3-ce89-49dd4f6c6aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7cXRMgYK2Bp",
        "outputId": "00e134d1-4f6d-46bf-b34b-bdcf1865d454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenizer.encode(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34MavtaaLUhr",
        "outputId": "8f800143-12cb-443d-a279-f94446a643da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "OWqjJK5iMne2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79nbLw0fMwll",
        "outputId": "cbbf087e-ce69-4765-eb13-a95a0464f191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ],
      "metadata": {
        "id": "LePCzS2dM1Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgMivUYHM8NS",
        "outputId": "2e886f47-3645-4709-f747-fa837451311c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SvnIvqxNIT5",
        "outputId": "db7bcf4f-f373-48e4-84e8-3243585d6d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE\n",
        "\n",
        "idxs = tokenizer.encode(\"Akwirw ier\")\n",
        "for id in idxs:\n",
        "  print(id, \"-->\", tokenizer.decode([id]))\n",
        "\n",
        "print('DECODING TOKEN IDS TO GET ORIGINAL TEXT:', ''.join([tokenizer.decode([id]) for id in idxs]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J61wOLEPRHpX",
        "outputId": "6a7f60d2-d231-4d1a-eac9-4dd9828bd5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33901 --> Ak\n",
            "86 --> w\n",
            "343 --> ir\n",
            "86 --> w\n",
            "220 -->  \n",
            "959 --> ier\n",
            "DECODING TOKEN IDS TO GET ORIGINAL TEXT: Akwirw ier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "nVW0x1lVbXWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "u6gu_p-QZ5Xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Build a LLM from scratch/the-verdict.txt\", 'r', encoding='utf-8') as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding('gpt2')\n",
        "\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_Cv0-73WFb3",
        "outputId": "ec6f6043-34bc-4593-d1dd-cdcf6cbd32ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[:50]\n",
        "\n",
        "context_size = 4\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y:      {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKBU9GL_WPop",
        "outputId": "c6330be6-c554-4c4e-877a-5e77f1fdf75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [40, 367, 2885, 1464]\n",
            "y:      [367, 2885, 1464, 1807]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = [enc_sample[:i+1] for i in range(len(enc_sample))]\n",
        "Y = enc_sample[1:]\n",
        "\n",
        "i = 0\n",
        "for x_el, y_el in zip(X, Y):\n",
        "  i += 1\n",
        "  if i > 5: break\n",
        "  print(\"INPUT IDS:\", x_el, \"<--->\", \"TARGET OUTPUT:\", y_el)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG_7gIxbXnOY",
        "outputId": "4c97fd14-eeb8-4a70-ed4b-29817d71a48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT IDS: [40] <---> TARGET OUTPUT: 367\n",
            "INPUT IDS: [40, 367] <---> TARGET OUTPUT: 2885\n",
            "INPUT IDS: [40, 367, 2885] <---> TARGET OUTPUT: 1464\n",
            "INPUT IDS: [40, 367, 2885, 1464] <---> TARGET OUTPUT: 1807\n",
            "INPUT IDS: [40, 367, 2885, 1464, 1807] <---> TARGET OUTPUT: 3619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = [enc_sample[:i+1] for i in range(len(enc_sample))]\n",
        "Y = enc_sample[1:]\n",
        "\n",
        "i = 0\n",
        "for x_el, y_el in zip(X, Y):\n",
        "  i += 1\n",
        "  if i > 5: break\n",
        "  print(\"INPUT TEXT:\", tokenizer.decode(x_el), \"<--->\", \"TARGET OUTPUT TEXT:\", tokenizer.decode([y_el]))"
      ],
      "metadata": {
        "id": "GPQcWlv7ZGxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d07cc9-583b-4a3a-b804-f8b322ad234a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT TEXT: I <---> TARGET OUTPUT TEXT:  H\n",
            "INPUT TEXT: I H <---> TARGET OUTPUT TEXT: AD\n",
            "INPUT TEXT: I HAD <---> TARGET OUTPUT TEXT:  always\n",
            "INPUT TEXT: I HAD always <---> TARGET OUTPUT TEXT:  thought\n",
            "INPUT TEXT: I HAD always thought <---> TARGET OUTPUT TEXT:  Jack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "\n",
        "    for i in range(0, len(token_ids)-max_length, stride):\n",
        "\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1:i+1+max_length]\n",
        "      self.input_ids.append(torch.Tensor(input_chunk))\n",
        "      self.target_ids.append(torch.Tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n"
      ],
      "metadata": {
        "id": "gVenPd1QbLBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "  dataloader = DataLoader(\n",
        "                          dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          drop_last=drop_last,\n",
        "                          num_workers=0\n",
        "                          )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "LVTEN7agbkem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzzjQHdRjLMU",
        "outputId": "743522b8-786d-4267-d57a-fbeef9b8f83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40.,  367., 2885., 1464.]]), tensor([[ 367., 2885., 1464., 1807.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MC5o6vfsBnh",
        "outputId": "fd513fb5-f16f-4629-b313-32ff6e2c52fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367., 2885., 1464., 1807.]]), tensor([[2885., 1464., 1807., 3619.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=8, stride=2, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)\n",
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CztFFcwJx9hA",
        "outputId": "d2c1a491-faa3-4fb7-e0e9-03c7fcdb4e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40.,  367., 2885., 1464., 1807., 3619.,  402.,  271.]]), tensor([[  367.,  2885.,  1464.,  1807.,  3619.,   402.,   271., 10899.]])]\n",
            "[tensor([[ 2885.,  1464.,  1807.,  3619.,   402.,   271., 10899.,  2138.]]), tensor([[ 1464.,  1807.,  3619.,   402.,   271., 10899.,  2138.,   257.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mSzw4U7yNoI",
        "outputId": "30c0237b-9127-447e-c341-97090a707a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[4.0000e+01, 3.6700e+02, 2.8850e+03, 1.4640e+03],\n",
            "        [1.8070e+03, 3.6190e+03, 4.0200e+02, 2.7100e+02],\n",
            "        [1.0899e+04, 2.1380e+03, 2.5700e+02, 7.0260e+03],\n",
            "        [1.5632e+04, 4.3800e+02, 2.0160e+03, 2.5700e+02],\n",
            "        [9.2200e+02, 5.8910e+03, 1.5760e+03, 4.3800e+02],\n",
            "        [5.6800e+02, 3.4000e+02, 3.7300e+02, 6.4500e+02],\n",
            "        [1.0490e+03, 5.9750e+03, 2.8400e+02, 5.0200e+02],\n",
            "        [2.8400e+02, 3.2850e+03, 3.2600e+02, 1.1000e+01]])\n",
            "\n",
            "Targets:\n",
            " tensor([[3.6700e+02, 2.8850e+03, 1.4640e+03, 1.8070e+03],\n",
            "        [3.6190e+03, 4.0200e+02, 2.7100e+02, 1.0899e+04],\n",
            "        [2.1380e+03, 2.5700e+02, 7.0260e+03, 1.5632e+04],\n",
            "        [4.3800e+02, 2.0160e+03, 2.5700e+02, 9.2200e+02],\n",
            "        [5.8910e+03, 1.5760e+03, 4.3800e+02, 5.6800e+02],\n",
            "        [3.4000e+02, 3.7300e+02, 6.4500e+02, 1.0490e+03],\n",
            "        [5.9750e+03, 2.8400e+02, 5.0200e+02, 2.8400e+02],\n",
            "        [3.2850e+03, 3.2600e+02, 1.1000e+01, 2.8700e+02]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLwN7-9pz1yK",
        "outputId": "6c8ccb91-a235-4510-a30a-77bdcbbf0c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jlGEkQb04lD",
        "outputId": "c1439a70-812c-4bbe-b465-98d15c2eadf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2, 3, 5, 1])\n",
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djIswvFb1BbS",
        "outputId": "d25e8fbe-686c-4530-8855-3461ce771a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "9TKil8XG2NoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "inputs = inputs.long()\n",
        "targets = targets.long()\n",
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"\\nInputs shape:\\n\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVRDgPkn49bB",
        "outputId": "fb016058-86cb-443c-c95f-39059ebebd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR_fdyT05Jal",
        "outputId": "e076d07d-583c-440c-ff69-5b553115fd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zl_9CcP5uR-",
        "outputId": "04a86809-7216-4243-add2-a45e897159ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgdt4n4L6A53",
        "outputId": "9d1e2208-21c8-43c4-f6f2-110faa350f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3"
      ],
      "metadata": {
        "id": "-2M6zch4W-vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "[[0.43, 0.15, 0.89], # Your(x^1)\n",
        "[0.55, 0.87, 0.66], # journey(x^2)\n",
        "[0.57, 0.85, 0.64], # starts(x^3)\n",
        "[0.22, 0.58, 0.33], # with(x^4)\n",
        "[0.77, 0.25, 0.10], # one(x^5)\n",
        "[0.05, 0.80, 0.55]] # step(x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "SarmwOqg6TDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  attn_scores_2[i] = torch.dot(x_i, query)\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoHlo8YydPSc",
        "outputId": "fd935403-0798-4819-800d-69c3a0a02ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
        "print(\"Attention weights:\", attn_weights_2_tmp)\n",
        "print(\"Sum:\", attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Glwv5WS5s-N",
        "outputId": "7106128a-2d42-4a4b-a4c1-5778803ed4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "Sum: tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_naive(x):\n",
        "  return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
        "\n",
        "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
        "print(\"Attention weights:\", attn_weights_2_naive)\n",
        "print(\"Sum:\", attn_weights_2_naive.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpoOt3-P5zAq",
        "outputId": "6bc994f0-6612-4adb-8562-543e11e4d79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
        "print(\"Attention weights:\", attn_weights_2)\n",
        "print(\"Sum:\", attn_weights_2.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGzZ0Lk76wL3",
        "outputId": "8c3b1d42-ea54-4cb8-d775-96a8dc8eff46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "\n",
        "for i,x_i in enumerate(inputs):\n",
        "  context_vec_2 += attn_weights_2[i]*x_i\n",
        "\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCKaQvS_7Fek",
        "outputId": "36dcd4da-2478-4703-f57e-8c6a2ef38d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = torch.empty(6, 6)\n",
        "\n",
        "for i, x_i in enumerate(inputs):\n",
        "  for j, x_j in enumerate(inputs):\n",
        "    attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "\n",
        "\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoK3kIns7-ql",
        "outputId": "bf5e5b0b-4cc8-45b7-8709-29b66e7cb262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUT-vCCc8Ezh",
        "outputId": "55e2a1c8-303c-4e42-911b-a27fd2981fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xnh1Q1c8P7g",
        "outputId": "bf640a7b-8bed-4cad-a404-7fe26e68b6d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
        "print(\"Row 2 sum:\", row_2_sum)\n",
        "print(\"All row sums:\", attn_weights.sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrS-w6GT8sQv",
        "outputId": "1129a4a1-598c-498b-de0c-362069549992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 2 sum: 1.0\n",
            "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vecs = attn_weights @ inputs\n",
        "print(all_context_vecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqqhs9tN9BYQ",
        "outputId": "f5a8f223-4f6e-466c-fcbf-68dddd29101a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Previous 2nd context vector:\", context_vec_2)"
      ],
      "metadata": {
        "id": "VwqoOa2mCK13",
        "outputId": "8c3f89fc-6819-4e21-aff7-47f9a7123466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2\n",
        "\n",
        "print('shape(d_in)', d_in)\n",
        "print('shape(d_out)', d_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2doU1EtP66xj",
        "outputId": "8db9e00e-208b-44ad-c399-01f94570b12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape(d_in) 3\n",
            "shape(d_out) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "qtNXR0B489oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "print(query_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYk_i2-j9Iw4",
        "outputId": "283f8009-32de-4ff4-85b4-f7a2722ba4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4306, 1.4551])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH5bj0u69i1u",
        "outputId": "f90684f1-19c4-4d98-8548-1310c2924942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys.shape: torch.Size([6, 2])\n",
            "values.shape: torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_2 = keys[1]\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSk2mliQ-XbJ",
        "outputId": "19a0a5af-5123-4acd-b99d-aef3000b1fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1eIH0xO-e4M",
        "outputId": "72ff6404-80eb-44cf-899e-97ceb3085e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = keys.shape[-1]\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
        "print(attn_weights_2)\n",
        "print(attn_weights_2.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1gmGTJK-x-b",
        "outputId": "2844f3cc-835b-4e01-ec35-eaead8f2cffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "id": "DU-Yp3VsCAzH",
        "outputId": "1caa6ffd-aacb-4d67-cfd8-ad66fa91fac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3061, 0.8210])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.d_in = d_in\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = x @ self.W_key\n",
        "    queries = x @ self.W_query\n",
        "    values = x @ self.W_value\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(\n",
        "    attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "vOQ-XCZVGx8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs5ReO7OanSk",
        "outputId": "c00765d7-5511-4787-c9a3-91cdeef20e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "ed9VY9S6bGE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(789)\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dly5JsYkdWEf",
        "outputId": "f668c04b-aa64-41b8-d092-0d81e9b4b777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0739,  0.0713],\n",
            "        [-0.0748,  0.0703],\n",
            "        [-0.0749,  0.0702],\n",
            "        [-0.0760,  0.0685],\n",
            "        [-0.0763,  0.0679],\n",
            "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIN9IGMlFtXW",
        "outputId": "9e040a84-5222-43f4-df5f-848c215ed756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
            "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
            "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeyRH2rvgOXK",
        "outputId": "51966a21-2eeb-4219-f0cf-bfcd229296eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights*mask_simple\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORHDwQaUgpg3",
        "outputId": "bd2a071a-7195-4e60-edcd-73cefaccfd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6QaupqmhCHk",
        "outputId": "3d502cfe-8a9d-4ef6-a5ca-7dca3f0f77da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLaqgBvQhvnh",
        "outputId": "99c1f706-0238-4839-b1f1-a4dd04d20994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
            "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
            "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
            "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWHo7r7Phxm5",
        "outputId": "a4233151-7baf-4096-8cd1-58993db7e1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "dropout = torch.nn.Dropout(0.5)\n",
        "example = torch.ones(6, 6)\n",
        "print(dropout(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJUazXskptpo",
        "outputId": "3f553735-7351-458b-b195-09f5e91f044d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2., 2., 2., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.],\n",
            "        [0., 0., 2., 0., 2., 0.],\n",
            "        [2., 2., 0., 0., 0., 2.],\n",
            "        [2., 0., 0., 0., 0., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "print(dropout(attn_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcS7fQkCsnNF",
        "outputId": "f030a335-c21e-4f4e-c863-c3b31a44c62f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPwRtnIssyKm",
        "outputId": "db294bc5-d78b-4741-e1f4-aabee9487254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    attn_scores = queries @ keys.transpose(1, 2)\n",
        "    attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "PlBm7RIYw9FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
        "context_vecs = ca(batch)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4rtOnYQxPNN",
        "outputId": "4ee26bc3-3874-44eb-fafd-7816735e683a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "    [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
        "    for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "rQRbf5KEE5VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "d_in, d_out = 3, 2\n",
        "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpI5rUXlMnkJ",
        "outputId": "7c528256-5d4b-41e0-d7dd-a565706b36ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
            "\n",
            "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
        "                    [0.8993, 0.0390, 0.9268, 0.7388],\n",
        "                    [0.7179, 0.7058, 0.9156, 0.4340]],\n",
        "\n",
        "                    [[0.0772, 0.3565, 0.1479, 0.5331],\n",
        "                    [0.4066, 0.2318, 0.4545, 0.9737],\n",
        "                    [0.4606, 0.5159, 0.4220, 0.5786]]]])"
      ],
      "metadata": {
        "id": "hXncwDKGVwrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.transpose(2, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PXp-MtjV4Bn",
        "outputId": "c1d17812-3dd4-4fe0-b6cb-a31283c29a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.2745, 0.8993, 0.7179],\n",
            "          [0.6584, 0.0390, 0.7058],\n",
            "          [0.2775, 0.9268, 0.9156],\n",
            "          [0.8573, 0.7388, 0.4340]],\n",
            "\n",
            "         [[0.0772, 0.4066, 0.4606],\n",
            "          [0.3565, 0.2318, 0.5159],\n",
            "          [0.1479, 0.4545, 0.4220],\n",
            "          [0.5331, 0.9737, 0.5786]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a @ a.transpose(2, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIIlj01xV17T",
        "outputId": "24e8fc5a-276d-42a2-afb6-fb948172a246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1.3208, 1.1631, 1.2879],\n",
            "          [1.1631, 2.2150, 1.8424],\n",
            "          [1.2879, 1.8424, 2.0402]],\n",
            "\n",
            "         [[0.4391, 0.7003, 0.5903],\n",
            "          [0.7003, 1.3737, 1.0620],\n",
            "          [0.5903, 1.0620, 0.9912]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_head = a[0, 0, :, :]\n",
        "first_res = first_head @ first_head.T\n",
        "print(\"First head:\\n\", first_res)\n",
        "second_head = a[0, 1, :, :]\n",
        "second_res = second_head @ second_head.T\n",
        "print(\"\\nSecond head:\\n\", second_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ilo9tyEWRYf",
        "outputId": "dd4ad009-a480-49cd-e06c-7a00cfa2fc56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First head:\n",
            " tensor([[1.3208, 1.1631, 1.2879],\n",
            "        [1.1631, 2.2150, 1.8424],\n",
            "        [1.2879, 1.8424, 2.0402]])\n",
            "\n",
            "Second head:\n",
            " tensor([[0.4391, 0.7003, 0.5903],\n",
            "        [0.7003, 1.3737, 1.0620],\n",
            "        [0.5903, 1.0620, 0.9912]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert d_out % num_heads == 0\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "    'mask',\n",
        "    torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    keys = keys.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "    attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "    attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "    context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "    context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "Uue4Bj7wWe8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "batch_size, context_length, d_in = batch.shape\n",
        "d_out = 2\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4RSNEcrWatZ",
        "outputId": "08f6e8ee-5697-4b4a-f68f-ae8436c1604b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.3190, 0.4858],\n",
            "         [0.2943, 0.3897],\n",
            "         [0.2856, 0.3593],\n",
            "         [0.2693, 0.3873],\n",
            "         [0.2639, 0.3928],\n",
            "         [0.2575, 0.4028]],\n",
            "\n",
            "        [[0.3190, 0.4858],\n",
            "         [0.2943, 0.3897],\n",
            "         [0.2856, 0.3593],\n",
            "         [0.2693, 0.3873],\n",
            "         [0.2639, 0.3928],\n",
            "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4"
      ],
      "metadata": {
        "id": "SPM0LefjXPvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "\"vocab_size\": 50257,\n",
        "\"context_length\": 1024,\n",
        "\"emb_dim\": 768,\n",
        "\"n_heads\": 12,\n",
        "\"n_layers\": 12,\n",
        "\"drop_rate\": 0.1,\n",
        "\"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "wb7xjjL2XSoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DummyGPTModel(nn.Module):\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "    self.trf_blocks = nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "    self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits\n",
        "\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x\n",
        "\n",
        "class DummyLayerNorm(nn.Module):\n",
        "\n",
        "  def __init__(self, normalized_shape, eps=1e-5):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x"
      ],
      "metadata": {
        "id": "dlf5ZfZayt-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnNuEhiM8Rep",
        "outputId": "57711b7a-de05-401a-b96d-09d2d1d199df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "batch = []\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)"
      ],
      "metadata": {
        "id": "fJyKYfPy1tfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b269c1a7-e888-4e7a-c91e-b8d791ad3345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "logits = model(batch)\n",
        "print(\"Output shape:\", logits.shape)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKss8oKJ8Wwl",
        "outputId": "845d9c41-e2e2-48c7-c75c-fbccd8e10efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
            "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
            "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
            "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
            "\n",
            "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
            "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
            "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
            "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "batch_example = torch.randn(2, 5)\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch_example)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0bu6_oO8fZt",
        "outputId": "791465bf-47fa-4ed6-d2a0-737140295da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "var = out.var(dim=-1, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1nGYdv_Bh1P",
        "outputId": "252dfa40-8f29-4f74-ba5d-bcb1ed0b3d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[0.1324],\n",
            "        [0.2170]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[0.0231],\n",
            "        [0.0398]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_norm = (out - mean) / torch.sqrt(var)\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(\"Normalized layer outputs:\\n\", out_norm)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0euDkRgCMcc",
        "outputId": "5668c0da-78f8-45ad-ae15-3e171b4bc7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized layer outputs:\n",
            " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
            "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Mean:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCAuXAs3CXA6",
        "outputId": "43e94521-3b68-4aca-98f1-51084d60f6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "cXFg7ydKCbBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "out_ln = ln(batch_example)\n",
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WS3DZ3QCjFb",
        "outputId": "fd9de8dd-56a0-4e30-83f4-8ad3b485f217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    -0.0000],\n",
            "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "   super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "   return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
      ],
      "metadata": {
        "id": "_7wk73G6DKTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "plt.figure(figsize=(8, 3))\n",
        "\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "  plt.subplot(1, 2, i)\n",
        "  plt.plot(x, y)\n",
        "  plt.title(f\"{label} activation function\")\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.ylabel(f\"{label}(x)\")\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "id": "bej0ZImWFlYF",
        "outputId": "e1967c47-0f81-48e3-e9d1-a50c02ad6f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "                                nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "                                GELU(),\n",
        "                                nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "                                )\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "daRFYtnsF3Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "x = torch.rand(2, 3, 768)\n",
        "out = ffn(x)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68QCGwznGOzm",
        "outputId": "900229dc-5e46-4fde-c825-05e30fb2bc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self, layer_sizes, use_shortcut):\n",
        "    super().__init__()\n",
        "    self.use_shortcut = use_shortcut\n",
        "    self.layers = nn.ModuleList([\n",
        "                                nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
        "                                nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
        "                                nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
        "                                nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
        "                                nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
        "                                ])\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      layer_output = layer(x)\n",
        "      if self.use_shortcut and x.shape == layer_output.shape:\n",
        "        x = x + layer_output\n",
        "      else:\n",
        "        x = layer_output\n",
        "    return x"
      ],
      "metadata": {
        "id": "MwiTVVMOGkP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "torch.manual_seed(123)\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
      ],
      "metadata": {
        "id": "BhCzPUaCJsJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gradients(model, x):\n",
        "  output = model(x)\n",
        "  target = torch.tensor([[0.]])\n",
        "  loss = nn.MSELoss()\n",
        "  loss = loss(output, target)\n",
        "  loss.backward()\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "     print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ],
      "metadata": {
        "id": "4u4Ra5yUJ4aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gradients(model_without_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NgHzd6eKLla",
        "outputId": "4c90f651-f715-44b6-f480-aeee15bae08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.00040347169851884246\n",
            "layers.1.0.weight has gradient mean of 0.00024022319121286273\n",
            "layers.2.0.weight has gradient mean of 0.0014304080978035927\n",
            "layers.3.0.weight has gradient mean of 0.002797747263684869\n",
            "layers.4.0.weight has gradient mean of 0.010099290870130062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
        "print_gradients(model_with_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsSkluX1Mgrv",
        "outputId": "1dd832e0-3cd1-409c-eb13-fc0fe92c3306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
            "layers.1.0.weight has gradient mean of 0.20694105327129364\n",
            "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
            "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
            "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert d_out % num_heads == 0\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "    'mask',\n",
        "    torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    keys = keys.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "    attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "    attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "    context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "    context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "L6puSUb0PfF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "                                  d_in=cfg[\"emb_dim\"],\n",
        "                                  d_out=cfg[\"emb_dim\"],\n",
        "                                  context_length=cfg[\"context_length\"],\n",
        "                                  num_heads=cfg[\"n_heads\"],\n",
        "                                  dropout=cfg[\"drop_rate\"],\n",
        "                                  qkv_bias=cfg[\"qkv_bias\"])\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x"
      ],
      "metadata": {
        "id": "_nQ7O71aPR9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "x = torch.rand(2, 4, 768)\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(x)\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8I3pVcQPoxV",
        "outputId": "48357a6b-dd66-4b98-f859-d4a1c7e9befa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "    self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "WBKYoiD8P5Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hew84HIfT8hC",
        "outputId": "5f8f9ed0-8c86-4f6c-eb76-57a619ab67db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n",
            "\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[ 0.1381,  0.0077, -0.1963,  ..., -0.0222, -0.1060,  0.1717],\n",
            "         [ 0.3865, -0.8408, -0.6564,  ..., -0.5163,  0.2369, -0.3357],\n",
            "         [ 0.6989, -0.1829, -0.1631,  ...,  0.1472, -0.6504, -0.0056],\n",
            "         [-0.4290,  0.1669, -0.1258,  ...,  1.1579,  0.5303, -0.5549]],\n",
            "\n",
            "        [[ 0.1094, -0.2894, -0.1467,  ..., -0.0557,  0.2911, -0.2824],\n",
            "         [ 0.0882, -0.3552, -0.3527,  ...,  1.2930,  0.0053,  0.1898],\n",
            "         [ 0.6091,  0.4702, -0.4094,  ...,  0.7688,  0.3787, -0.1974],\n",
            "         [-0.0612, -0.0737,  0.4751,  ...,  1.2463, -0.3834,  0.0609]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap4fm8KTUbs_",
        "outputId": "b3536bfd-d27b-4db5-fc92-78f0e3c475a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,009,536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riCdrttaUwSV",
        "outputId": "5532af59-8b06-4fec-a087-07dad22f6730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
        "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olPeI6uiVJ2b",
        "outputId": "bfe2a1b9-a7a8-47e9-da93-be0abf1ad09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters considering weight tying: 124,412,160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_size_bytes = total_params * 4\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdDUNrPiVNE3",
        "outputId": "fad5d196-3718-4051-827d-82303764536a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the model: 621.83 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "g69B2VO3Vh7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJfrcwQFXaGF",
        "outputId": "68c54af1-58de-490c-8a58-636372ec1b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "out = generate_text_simple(\n",
        "                            model=model,\n",
        "                            idx=encoded_tensor,\n",
        "                            max_new_tokens=6,\n",
        "                            context_size=GPT_CONFIG_124M[\"context_length\"])\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBnAL2-pXlJh",
        "outputId": "c5ff5697-8864-4b3e-c073-a38eef524cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
            "Output length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn1ZwBH2XxO3",
        "outputId": "83d131b5-7055-4f5a-eb03-1f401d5d0800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am Featureiman Byeswickattribute argue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "      \"vocab_size\": 50257,\n",
        "      \"context_length\": 256,\n",
        "      \"emb_dim\": 768,\n",
        "      \"n_heads\": 12,\n",
        "      \"n_layers\": 12,\n",
        "      \"drop_rate\": 0.1,\n",
        "      \"qkv_bias\": False\n",
        "      }\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EN1WEQKjndG",
        "outputId": "d18b4941-4279-4835-fd28-51907e8edf9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        "                                  model=model,\n",
        "                                  idx=text_to_token_ids(start_context, tokenizer),\n",
        "                                  max_new_tokens=10,\n",
        "                                  context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        "                                  )\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2uUH3DHkw1I",
        "outputId": "b94a2242-53e5-4de4-fdb7-1b52628c29d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you forward, but you must be careful. You must\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],# [\"every effort moves\",\n",
        "                        [40, 1107, 588]]) #\"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345], # [\" effort moves you\",\n",
        "                         [1107, 588, 11311]]) #\" really like chocolate\"]"
      ],
      "metadata": {
        "id": "_eTexdZmrMnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(inputs)\n",
        "probas = torch.softmax(logits, dim=-1)\n",
        "print(probas.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ck2S1OlFGh",
        "outputId": "1d790277-013d-4ea3-973a-a017ef611d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iml0Lft9rxKi",
        "outputId": "0e2fdda5-9f16-417c-9943-d435f9051685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgzcfl9nr-o_",
        "outputId": "762035f6-d0fe-4001-a1b6-d18a4a3bbafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  Armed heNetflix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(sci_mode=True)"
      ],
      "metadata": {
        "id": "Nv3unBR0srPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y36-R44Vsdlo",
        "outputId": "732abeec-61e0-40c8-f4d2-68a704c3284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
            "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmc7IctotThu",
        "outputId": "6c86bcd5-0b8f-42b8-ebc5-e7086811e4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-9.5042e+00, -1.0380e+01, -1.1368e+01, -1.1480e+01, -9.7764e+00, -1.2256e+01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_tRsThPtUtO",
        "outputId": "0015b600-08fc-4ba7-dfab-9e499bd98a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1.0794e+01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaufyviVtnO-",
        "outputId": "bf90bb2a-eacb-4c12-8f01-cd5dfe572697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0794e+01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logits shape:\", logits.shape)\n",
        "print(\"Targets shape:\", targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv9yk-21tuj8",
        "outputId": "9bfdaf5b-62c6-482e-af06-2e831626e4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw5JSQJguK2O",
        "outputId": "9d648181-cac3-4aa4-9ba3-7aa5d681ba69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3p1_LbdulUJ",
        "outputId": "e103e44c-ee09-44a7-cbb1-bde07b2ad77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.0794e+01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = torch.exp(loss)\n",
        "perplexity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e4CZP2duoU-",
        "outputId": "23cbb6af-2dfb-4200-9b69-4796cb5f8f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.8726e+04)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Build a LLM from scratch/the-verdict.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  text_data = file.read()"
      ],
      "metadata": {
        "id": "Nt0kmxoevZyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MldCkTsR1RLo",
        "outputId": "9734b3f2-65fa-433b-8751-d7d0b521cad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "FeLHr8Ic2Vh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "\n",
        "    for i in range(0, len(token_ids)-max_length, stride):\n",
        "\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1:i+1+max_length]\n",
        "      self.input_ids.append(torch.Tensor(input_chunk).long())\n",
        "      self.target_ids.append(torch.Tensor(target_chunk).long())\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "E0pZo6rY2f6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "  dataloader = DataLoader(\n",
        "                          dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          drop_last=drop_last,\n",
        "                          num_workers=0\n",
        "                          )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "nIOEVsfD2pQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "                    train_data,\n",
        "                    batch_size=2,\n",
        "                    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "                    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "                    drop_last=True,\n",
        "                    shuffle=True,\n",
        "                    num_workers=0\n",
        "                    )\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "                    val_data,\n",
        "                    batch_size=2,\n",
        "                    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "                    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "                    drop_last=False,\n",
        "                    shuffle=False,\n",
        "                    num_workers=0\n",
        "                    )"
      ],
      "metadata": {
        "id": "BTb1teKS2XEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "  print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "  print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytQVK0Pe2ush",
        "outputId": "cab10908-3f1d-49e0-f170-8d83d8a13af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "  return loss"
      ],
      "metadata": {
        "id": "ysj1FTvU3H9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "-DH4PJOK3UFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUVl32RI3n0Z",
        "outputId": "6874679f-952d-42a0-9edc-c2332a894b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.987583584255642\n",
            "Validation loss: 10.98110580444336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "GOjuoL57ERAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "  model.eval()\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(\n",
        "                    model=model, idx=encoded,\n",
        "                    max_new_tokens=50, context_size=context_size\n",
        "                    )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "7nPXJk7hEjzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
        "  train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "  tokens_seen, global_step = 0, -1\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tokens_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "      if global_step % eval_freq == 0:\n",
        "\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "              f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "    generate_and_print_sample(model, tokenizer, device, start_context)\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "NuuRx-Tr46kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "                    model, train_loader, val_loader, optimizer, device,\n",
        "                    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
        "                    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWJbVB3kEw65",
        "outputId": "aeeb497a-65f0-4733-f8b4-f52b5aef3792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.830, Val loss 9.927\n",
            "Ep 1 (Step 000005): Train loss 8.133, Val loss 8.335\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.770, Val loss 7.048\n",
            "Ep 2 (Step 000015): Train loss 6.497, Val loss 6.573\n",
            "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,,,,, and,,,, and,, and,,,,, and,,,,,,\n",
            "Ep 3 (Step 000020): Train loss 5.579, Val loss 6.490\n",
            "Ep 3 (Step 000025): Train loss 4.732, Val loss 6.387\n",
            "Every effort moves you, and to the picture.                      \"I, and the of the of the's the honour, and, and I had been, and I\n",
            "Ep 4 (Step 000030): Train loss 5.284, Val loss 6.360\n",
            "Ep 4 (Step 000035): Train loss 3.855, Val loss 6.258\n",
            "Every effort moves you of the to the picture--as of the picture--as I had been \" it was his \" I was the     \"I was his I had been the his pictures--and it the picture and I had been the picture of\n",
            "Ep 5 (Step 000040): Train loss 3.667, Val loss 6.196\n",
            "Every effort moves you know the \"Oh, and he was not the fact by his last word.         \"I was.      \"Oh, I felt a little a little the    \n",
            "Ep 6 (Step 000045): Train loss 3.600, Val loss 6.139\n",
            "Ep 6 (Step 000050): Train loss 2.383, Val loss 6.112\n",
            "Every effort moves you know; and my dear, and he was not the fact with a little of the house of the fact of the fact, and.                       \n",
            "Ep 7 (Step 000055): Train loss 2.336, Val loss 6.138\n",
            "Ep 7 (Step 000060): Train loss 2.696, Val loss 6.179\n",
            "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I looked--as of the fact, and I felt him--his back his head to the donkey. \"Oh, and_--because he had always _\n",
            "Ep 8 (Step 000065): Train loss 1.596, Val loss 6.176\n",
            "Ep 8 (Step 000070): Train loss 1.346, Val loss 6.178\n",
            "Every effort moves you?\" \"I didn't bear the picture--I told me.  \"I looked up, and went on groping and Mrs. I was back the head to look up at the honour being _mine_--because he was when I\n",
            "Ep 9 (Step 000075): Train loss 1.100, Val loss 6.277\n",
            "Ep 9 (Step 000080): Train loss 0.672, Val loss 6.281\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 10 (Step 000085): Train loss 0.531, Val loss 6.325\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "  ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "  ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "  ax2.set_xlabel(\"Tokens seen\")\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "vy1eY4DEGUzZ",
        "outputId": "55edb590-9d8f-453a-f3b6-c3b6a3490928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjFYcfIvIAIe",
        "outputId": "4432c601-c82e-4833-8f9e-3818de94f6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        "                  model=model,\n",
        "                  idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "                  max_new_tokens=25,\n",
        "                  context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        "                  )\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIs2qBp-IBCT",
        "outputId": "a0e240c0-e4d0-41e3-ef95-33edccb42676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        "\"closer\": 0,\n",
        "\"every\": 1,\n",
        "\"effort\": 2,\n",
        "\"forward\": 3,\n",
        "\"inches\": 4,\n",
        "\"moves\": 5,\n",
        "\"pizza\": 6,\n",
        "\"toward\": 7,\n",
        "\"you\": 8,\n",
        "}\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ],
      "metadata": {
        "id": "tEj2wxY4OSv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits = torch.tensor(\n",
        "[4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")"
      ],
      "metadata": {
        "id": "EzbWvbN5Oci_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTRb4_8yOf0J",
        "outputId": "5f00680c-b5c4-4e5e-bafd-d77dcdc43c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55oghYWROm7m",
        "outputId": "642a9184-a6ae-44fa-df39-b7a20b3a94d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_sampled_tokens(probas):\n",
        "  torch.manual_seed(123)\n",
        "  sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
        "  sampled_ids = torch.bincount(torch.tensor(sample))\n",
        "  for i, freq in enumerate(sampled_ids):\n",
        "    print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "print_sampled_tokens(probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWD5aVeKOueW",
        "outputId": "0a7af179-8600-4965-bbb8-7af5b6c18630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71 x closer\n",
            "2 x every\n",
            "0 x effort\n",
            "544 x forward\n",
            "2 x inches\n",
            "1 x moves\n",
            "0 x pizza\n",
            "376 x toward\n",
            "4 x you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "  scaled_logits = logits / temperature\n",
        "  return torch.softmax(scaled_logits, dim=0)"
      ],
      "metadata": {
        "id": "Kg0MsfTuPQNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperatures = [1, 0.1, 5]\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "  rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "xRo7dRzDPSNd",
        "outputId": "883051d6-7a56-4180-fa69-0ab3a3a3c3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSu0BYg_Q5yO",
        "outputId": "68aeebec-8d3e-49b8-a404-99de94bf2494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500e+00, 6.2800e+00, 4.5100e+00])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        "              condition=next_token_logits < top_logits[-1],\n",
        "              input=torch.tensor(float('-inf')),\n",
        "              other=next_token_logits\n",
        "              )\n",
        "print(new_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGftNZSRR3pj",
        "outputId": "778e697f-012d-413a-bef8-71930215d30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100e+00,   -inf,   -inf, 6.7500e+00,   -inf,   -inf,   -inf, 6.2800e+00,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldSb3HUcR83u",
        "outputId": "67d7767c-9b0d-4ca7-f1a1-7d995b8c1d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6.1485e-02, 0.0000e+00, 0.0000e+00, 5.7755e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6097e-01, 0.0000e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=1.0, top_k=None, eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "    if top_k is not None:\n",
        "      top_logits, _ = torch.topk(logits, top_k)\n",
        "      min_val = top_logits[:, -1]\n",
        "      logits = torch.where(\n",
        "                  logits < min_val,\n",
        "                  torch.tensor(float('-inf')).to(logits.device),\n",
        "                  logits\n",
        "                  )\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "      probs = torch.softmax(logits, dim=-1)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "    else:\n",
        "      idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx"
      ],
      "metadata": {
        "id": "GAl6q99nSIcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        "              model=model,\n",
        "              idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "              max_new_tokens=15,\n",
        "              context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "              top_k=25,\n",
        "              temperature=1.4\n",
        "              )\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO7z_1PeS881",
        "outputId": "116f7ba3-cef9-4e3b-cb51-f7908b9f1cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know began to my surprise, a little it was the\n",
            "\"Ah enough\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/model.pth\")"
      ],
      "metadata": {
        "id": "EGm1ASTYXrkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load(\"/content/model.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKEdC5EyX9ht",
        "outputId": "98a0a26c-7d5a-4422-f6ed-a95b4c7c5b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "\"model_state_dict\": model.state_dict(),\n",
        "\"optimizer_state_dict\": optimizer.state_dict(),\n",
        "},\n",
        "\"/content/model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "zVK9umtAYDhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"/content/model_and_optimizer.pth\")\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "_sWEv_F3YSDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow>=2.15.0\n",
        "!pip install tqdm>=4.66"
      ],
      "metadata": {
        "id": "w2pshls4Yluw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\n",
        "\"https://raw.githubusercontent.com/rasbt/\"\n",
        "\"LLMs-from-scratch/main/ch05/\"\n",
        "\"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdMM44i3amkZ",
        "outputId": "fba88ede-1202-48f7-dd9f-6dd988029849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7d7558baca30>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "3_zmF0UjarAn",
        "outputId": "af1b20db-4dec-4c2e-e92b-b1d13f62e7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gpt_download'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-df4321e68f9d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgpt_download\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_and_load_gpt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_load_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"124M\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_download'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLRWnDala-2J",
        "outputId": "62760820-4b2a-4ad0-8580-5d28bb47d580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrcQ5ksPbC1X",
        "outputId": "15b4b70f-c745-475d-ce67-dcc7361f29a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "rf_e3b2TbN51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2-small (124M)\"\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])"
      ],
      "metadata": {
        "id": "m9Klsf-lbcFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024})"
      ],
      "metadata": {
        "id": "adRJqu5KbmCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"qkv_bias\": True})\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw6nL9ypbogg",
        "outputId": "e3abbe16-f8d6-4142-b688-74b6042c8d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "  if left.shape != right.shape:\n",
        "    raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "  return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "lnRNQ0wxbw9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "  gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "  gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "  for b in range(len(params[\"blocks\"])):\n",
        "\n",
        "    q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.weight = assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "    gpt.trf_blocks[b].att.W_key.weight = assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "    gpt.trf_blocks[b].att.W_value.weight = assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "    q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.bias = assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "    gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "    gpt.trf_blocks[b].att.W_value.bias = assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "    gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "                                              gpt.trf_blocks[b].att.out_proj.weight,\n",
        "                                              params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "                                              gpt.trf_blocks[b].att.out_proj.bias,\n",
        "                                              params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "                                              gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "                                              params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "                                              gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "                                              params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "                                              gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "                                              params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "                                              gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "                                              params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm1.scale = assign(\n",
        "                                              gpt.trf_blocks[b].norm1.scale,\n",
        "                                              params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm1.shift = assign(\n",
        "                                              gpt.trf_blocks[b].norm1.shift,\n",
        "                                              params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm2.scale = assign(\n",
        "                                              gpt.trf_blocks[b].norm2.scale,\n",
        "                                              params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm2.shift = assign(\n",
        "                                              gpt.trf_blocks[b].norm2.shift,\n",
        "                                              params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "HZvfINdrcDMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3oJMYQXd1lg",
        "outputId": "f798ade5-bfb4-40f7-ff39-c29f739f3cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        "              model=gpt,\n",
        "              idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "              max_new_tokens=25,\n",
        "              context_size=NEW_CONFIG[\"context_length\"],\n",
        "              top_k=50,\n",
        "              temperature=0.1\n",
        "              )\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ush95snId3wB",
        "outputId": "a6120d9e-572a-400d-cc59-9958399323a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you forward.\n",
            "\n",
            "The next time you see a person who is not a good person, ask yourself, \"What is the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6"
      ],
      "metadata": {
        "id": "OX_GtHOpeWXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "\n",
        "  if data_file_path.exists():\n",
        "    print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "    return\n",
        "\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    with open(zip_path, \"wb\") as out_file:\n",
        "      out_file.write(response.read())\n",
        "\n",
        "  with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "  original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "  os.rename(original_file_path, data_file_path)\n",
        "  print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb_GrYd2eYLH",
        "outputId": "00ef2d54-1ee2-4711-d3a6-5d3b64b12786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Zd7vRwONwAXQ",
        "outputId": "7796892d-4d10-4aa3-aba7-296fdb988d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c8985b6-fe74-46bd-94ab-e6991018b5a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c8985b6-fe74-46bd-94ab-e6991018b5a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c8985b6-fe74-46bd-94ab-e6991018b5a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c8985b6-fe74-46bd-94ab-e6991018b5a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9d35070e-3838-42c6-9e90-fc44b5ce8258\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d35070e-3838-42c6-9e90-fc44b5ce8258')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9d35070e-3838-42c6-9e90-fc44b5ce8258 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_69c6922f-d6d1-4d26-80e4-accd8b019c95\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_69c6922f-d6d1-4d26-80e4-accd8b019c95 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kowZyKYQwJqh",
        "outputId": "689dca4d-51dc-4fe0-b2f8-4c1a4e62a00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "  num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "  ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "  balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "  return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I44S6bcwK-a",
        "outputId": "258e4a61-da6f-4957-cfa0-60b2b9c4819a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "balanced_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SppGqT1RwfJT",
        "outputId": "10257ea8-3691-41f5-a7fc-9db17ee862de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                               Text\n",
              "4307      0  Awww dat is sweet! We can think of something t...\n",
              "4138      0                             Just got to  &lt;#&gt;\n",
              "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
              "4461      0  This is wishing you a great day. Moji told me ...\n",
              "5440      0      Thank you. do you generally date the brothas?"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e2d9fa7-efbf-4b29-aae9-259ef5644494\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4307</th>\n",
              "      <td>0</td>\n",
              "      <td>Awww dat is sweet! We can think of something t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4138</th>\n",
              "      <td>0</td>\n",
              "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4831</th>\n",
              "      <td>0</td>\n",
              "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4461</th>\n",
              "      <td>0</td>\n",
              "      <td>This is wishing you a great day. Moji told me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5440</th>\n",
              "      <td>0</td>\n",
              "      <td>Thank you. do you generally date the brothas?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e2d9fa7-efbf-4b29-aae9-259ef5644494')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e2d9fa7-efbf-4b29-aae9-259ef5644494 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e2d9fa7-efbf-4b29-aae9-259ef5644494');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1817e672-fe27-441d-a526-384092c20163\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1817e672-fe27-441d-a526-384092c20163')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1817e672-fe27-441d-a526-384092c20163 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_df",
              "summary": "{\n  \"name\": \"balanced_df\",\n  \"rows\": 1494,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1388,\n        \"samples\": [\n          \"chile, please! It's only a  &lt;DECIMAL&gt;  hour drive for me. I come down all the time and will be subletting feb-april for audition season.\",\n          \"I only haf msn. It's yijue@hotmail.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "  df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "  train_end = int(len(df) * train_frac)\n",
        "  validation_end = train_end + int(len(df) * validation_frac)\n",
        "  train_df = df[:train_end]\n",
        "  validation_df = df[train_end:validation_end]\n",
        "  test_df = df[validation_end:]\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "id": "fmVgkpRgw4JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "7C02jwoixL3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FLEdcdVB7O5",
        "outputId": "038c35f2-7c27-4f2e-c7b2-394f4c067f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiVOhP68xQML",
        "outputId": "b5ef54e3-dd13-4c58-a617-527b38c2e489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "\n",
        "  def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
        "\n",
        "    if max_length is None:\n",
        "      self.max_length = self._longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length = max_length\n",
        "\n",
        "      self.encoded_texts = [encoded_text[:self.max_length]\n",
        "                            for encoded_text in self.encoded_texts]\n",
        "\n",
        "    self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "                          for encoded_text in self.encoded_texts]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    encoded = self.encoded_texts[index]\n",
        "    label = self.data.iloc[index][\"Label\"]\n",
        "    return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "          torch.tensor(label, dtype=torch.long)\n",
        "          )\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def _longest_encoded_length(self):\n",
        "    max_length = 0\n",
        "    for encoded_text in self.encoded_texts:\n",
        "      encoded_length = len(encoded_text)\n",
        "      if encoded_length > max_length:\n",
        "        max_length = encoded_length\n",
        "    return max_length"
      ],
      "metadata": {
        "id": "XiOTZzeF1UXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        "csv_file=\"train.csv\",\n",
        "max_length=None,\n",
        "tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "Y2rDm03K1lH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33zb2zbz1pzl",
        "outputId": "cd9a7e16-f43e-4461-861e-c15bfd2a1c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        "                csv_file=\"validation.csv\",\n",
        "                max_length=train_dataset.max_length,\n",
        "                tokenizer=tokenizer\n",
        "                )\n",
        "\n",
        "test_dataset = SpamDataset(\n",
        "                csv_file=\"test.csv\",\n",
        "                max_length=train_dataset.max_length,\n",
        "                tokenizer=tokenizer\n",
        "                )"
      ],
      "metadata": {
        "id": "Y7511XBP2sNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "                dataset=train_dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                num_workers=num_workers,\n",
        "                drop_last=True,\n",
        "                )\n",
        "\n",
        "val_loader = DataLoader(\n",
        "                dataset=val_dataset,\n",
        "                batch_size=batch_size,\n",
        "                num_workers=num_workers,\n",
        "                drop_last=False,\n",
        "                )\n",
        "\n",
        "test_loader = DataLoader(\n",
        "                dataset=test_dataset,\n",
        "                batch_size=batch_size,\n",
        "                num_workers=num_workers,\n",
        "                drop_last=False,\n",
        "                )"
      ],
      "metadata": {
        "id": "-SA0okzM2wj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_loader:\n",
        "  pass\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJaWpCtD3ZDM",
        "outputId": "fa7e342a-2d18-486c-ed74-389fb51960d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvJ9kBXk3kjM",
        "outputId": "16dc0504-c406-40ee-b915-01f0363a4677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "BASE_CONFIG = {\n",
        "              \"vocab_size\": 50257,\n",
        "              \"context_length\": 1024,\n",
        "              \"drop_rate\": 0.0,\n",
        "              \"qkv_bias\": True\n",
        "              }\n",
        "\n",
        "model_configs = {\n",
        "                \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "                \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "                \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "                \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "\n",
        "                }\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "              f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "              f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "              f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        "              )"
      ],
      "metadata": {
        "id": "ZlvIHjAS3rW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S50SVLuc4DO7",
        "outputId": "ee9c0cf4-8793-4542-d233-f6437126b5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"Every effort moves you\"\n",
        "token_ids = generate_text_simple(\n",
        "model=model,\n",
        "idx=text_to_token_ids(text_1, tokenizer),\n",
        "max_new_tokens=15,\n",
        "context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0YMs94a4L7T",
        "outputId": "8bca186d-3452-43fb-c020-01399dc1e332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "\"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "\" 'You are a winner you have been specially\"\n",
        "\" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "token_ids = generate_text_simple(\n",
        "model=model,\n",
        "idx=text_to_token_ids(text_2, tokenizer),\n",
        "max_new_tokens=23,\n",
        "context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg_DgxYt4TbY",
        "outputId": "d771a9da-14cb-43bb-9561-a047a1fdec0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsx3VTx-5HJE",
        "outputId": "d4ab6c5d-017d-4df5-8696-8a1afa41986e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "HpScB2sW5KD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(\n",
        "                        in_features=BASE_CONFIG[\"emb_dim\"],\n",
        "                        out_features=num_classes\n",
        "                        )"
      ],
      "metadata": {
        "id": "LVVVG3ow5fyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "  param.requires_grad = True\n",
        "for param in model.final_norm.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "OUJjmikd5q28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LifWcIN55Te",
        "outputId": "52af4b7a-339e-4c0f-e2e7-f79c6c3f8bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(inputs)\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZdgLy1U6H0o",
        "outputId": "c3e6fef7-9924-4769-d388-38e5a01ada19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5854e+00, 9.9035e-01],\n",
            "         [-3.7235e+00, 7.4548e+00],\n",
            "         [-2.2661e+00, 6.6049e+00],\n",
            "         [-3.5983e+00, 3.9902e+00]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJq9AMDl6NtX",
        "outputId": "2b266c44-c337-46ad-ccc3-bcdc7d4b44c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983e+00, 3.9902e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "label = torch.argmax(probas)\n",
        "print(\"Class label:\", label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX0faGdC6i5H",
        "outputId": "c3fe68c2-e364-4af0-9a83-ea9f442b5624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD7KMTp98qzQ",
        "outputId": "02decd70-312a-49dc-8757-de1e0bc662d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions, num_examples = 0, 0\n",
        "\n",
        "  if num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "      with torch.no_grad():\n",
        "        logits = model(input_batch)[:, -1, :]\n",
        "      predicted_labels = torch.argmax(logits, dim=-1)\n",
        "      num_examples += predicted_labels.shape[0]\n",
        "      correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "    else:\n",
        "      break\n",
        "\n",
        "  return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "Pn-cAv8q8tQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6sPGem-C2Ws",
        "outputId": "af8d49a7-a164-46c5-c7f4-4a42ee9ff5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x795d44354c10>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)"
      ],
      "metadata": {
        "id": "p_6KUexj9HfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsG0qBYO9umo",
        "outputId": "fd2bc13e-1cad-4f86-c37b-e9ed0b4d2404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "  logits = model(input_batch)[:, -1, :]\n",
        "  loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "0tTeIL6W9yd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches\n",
        "\n"
      ],
      "metadata": {
        "id": "dTyeaaqG-HNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "  test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)"
      ],
      "metadata": {
        "id": "6vmtF-l3C8BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQK1h9yR-ixf",
        "outputId": "e8429001-5f07-46ee-d33a-1127d25cb73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.453\n",
            "Validation loss: 2.583\n",
            "Test loss: 2.322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device,\n",
        "num_epochs, eval_freq, eval_iter, tokenizer):\n",
        "\n",
        "  train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "  examples_seen, global_step = 0, -1\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      examples_seen += input_batch.shape[0]\n",
        "      global_step += 1\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "        f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "    train_accuracy = calc_accuracy_loader(\n",
        "    train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "\n",
        "    val_accuracy = calc_accuracy_loader(\n",
        "    val_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "\n",
        "    print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "    print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "\n",
        "    train_accs.append(train_accuracy)\n",
        "    val_accs.append(val_accuracy)\n",
        "\n",
        "  return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ],
      "metadata": {
        "id": "P678JyG--4JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "  model.train()\n",
        "  return train_loss, val_loss"
      ],
      "metadata": {
        "id": "WhdieqYC_2ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "                                                                    model, train_loader, val_loader, optimizer, device,\n",
        "                                                                    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        "                                                                    tokenizer=tokenizer\n",
        "                                                                    )\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LJMAR32_9_0",
        "outputId": "84782798-e15c-4927-9ae8-a0ddc0c942c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
            "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
            "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
            "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
            "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
            "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
            "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
            "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
            "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
            "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
            "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training completed in 0.96 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "  ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "  ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "  ax1.set_xlabel(\"Epochs\")\n",
        "  ax1.set_ylabel(label.capitalize())\n",
        "  ax1.legend()\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(examples_seen, train_values, alpha=0)\n",
        "  ax2.set_xlabel(\"Examples seen\")\n",
        "  fig.tight_layout()\n",
        "  plt.savefig(f\"{label}-plot.pdf\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "fS-lH9xHAOdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "drp-AUc0AV4W",
        "outputId": "90a97ec7-14ac-448b-ed19-636434119791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "g0hu4mRWAarN",
        "outputId": "6ffa5b1a-6ed1-44a9-812a-d8d83d33bec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VViw10BAf2Q",
        "outputId": "b0030a94-2c0b-48b9-c9ab-ee764003715a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 97.21%\n",
            "Validation accuracy: 97.32%\n",
            "Test accuracy: 95.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "  model.eval()\n",
        "  input_ids = tokenizer.encode(text)\n",
        "  supported_context_length = model.pos_emb.weight.shape[1]\n",
        "  input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "  input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "  input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor)[:, -1, :]\n",
        "  predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "  return \"spam\" if predicted_label == 1 else \"not spam\""
      ],
      "metadata": {
        "id": "wfHWovgeDurx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "\"You are a winner you have been specially\"\n",
        "\" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91-LtI_GD5nd",
        "outputId": "812770ba-2e02-46f5-d84f-c9762d223c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "\"Hey, just wanted to check if we're still on\"\n",
        "\" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRPFZ9CkEEby",
        "outputId": "00cf771f-9aa0-4cc9-988c-6123fc660a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "C5o-Q0uVEG2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\")\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Wzuop-ELak",
        "outputId": "801a0d20-b7a3-42c5-88cc-751207c14643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OZssxY8Eg0_",
        "outputId": "d22d50fd-d288-43eb-b968-38c494021490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 97.21%\n",
            "Validation accuracy: 97.32%\n",
            "Test accuracy: 95.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7"
      ],
      "metadata": {
        "id": "EhWWnJZIC7JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "  if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "      text_data = response.read().decode(\"utf-8\")\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "      file.write(text_data)\n",
        "  else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "      text_data = file.read()\n",
        "  with open(file_path, \"r\") as file:\n",
        "    data = json.load(file)\n",
        "  return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv8NaUqiLrZq",
        "outputId": "0e9d11b7-0250-4f87-ef44-66bb4891cb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3giMXqO4MGu9",
        "outputId": "a085d98b-5045-4fc7-badd-1d20dab9cc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlbsWyveUkSo",
        "outputId": "ee323cd2-774a-4310-827b-97c2cb6a4aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "  instruction_text = (\n",
        "  f\"Below is an instruction that describes a task. \"\n",
        "  f\"Write a response that appropriately completes the request.\"\n",
        "  f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "  )\n",
        "  input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "  return instruction_text + input_text"
      ],
      "metadata": {
        "id": "D2F8Bri8UqPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNAIO1IJV-Ws",
        "outputId": "39cd7528-238e-4024-dd43-5ad7b8684848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UIq-_ChWTH7",
        "outputId": "b3e9b9f2-2ddb-4768-b413-b33e9887c8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.85)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmit2JoLWeqU",
        "outputId": "fec9ff40-7bbe-49a4-96e9-7e9e8c79864b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.data = data\n",
        "    self.encoded_texts = []\n",
        "    for entry in data:\n",
        "      instruction_plus_input = format_input(entry)\n",
        "      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "      full_text = instruction_plus_input + response_text\n",
        "      self.encoded_texts.append(tokenizer.encode(full_text))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.encoded_texts[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "pLWESortWt2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIc5PPPSmnIp",
        "outputId": "6614c19f-db13-4b8b-bef0-0212cb585329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds5lRHOBmY5G",
        "outputId": "a7d44a7b-a860-4acb-edd4-e66e7f901632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
        "\n",
        "  batch_max_length = max(len(item)+1 for item in batch)\n",
        "  inputs_lst = []\n",
        "\n",
        "  for item in batch:\n",
        "    new_item = item.copy()\n",
        "    new_item += [pad_token_id]\n",
        "    padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "    inputs = torch.tensor(padded[:-1])\n",
        "    inputs_lst.append(inputs)\n",
        "\n",
        "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "\n",
        "  return inputs_tensor"
      ],
      "metadata": {
        "id": "gXqof6bzmwhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "batch = (\n",
        "inputs_1,\n",
        "inputs_2,\n",
        "inputs_3\n",
        ")\n",
        "print(custom_collate_draft_1(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSbRSfHHnOcp",
        "outputId": "ad2914ad-d998-43fb-e330-009fd335593f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
        "  batch_max_length = max(len(item)+1 for item in batch)\n",
        "  inputs_lst, targets_lst = [], []\n",
        "  for item in batch:\n",
        "    new_item = item.copy()\n",
        "    new_item += [pad_token_id]\n",
        "    padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "    inputs = torch.tensor(padded[:-1])\n",
        "    targets = torch.tensor(padded[1:])\n",
        "    inputs_lst.append(inputs)\n",
        "    targets_lst.append(targets)\n",
        "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "  targets_tensor = torch.stack(targets_lst).to(device)\n",
        "  return inputs_tensor, targets_tensor\n"
      ],
      "metadata": {
        "id": "Y3T6JGuhnS9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRYqVSgKsSL-",
        "outputId": "61edf8b5-7f2e-457d-d87d-7f4cae3cc950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
        "\n",
        "  batch_max_length = max(len(item)+1 for item in batch)\n",
        "  inputs_lst, targets_lst = [], []\n",
        "\n",
        "  for item in batch:\n",
        "\n",
        "    new_item = item.copy()\n",
        "    new_item += [pad_token_id]\n",
        "    padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "    inputs = torch.tensor(padded[:-1])\n",
        "    targets = torch.tensor(padded[1:])\n",
        "    mask = targets == pad_token_id\n",
        "    indices = torch.nonzero(mask).squeeze()\n",
        "\n",
        "    if indices.numel() > 1:\n",
        "      targets[indices[1:]] = ignore_index\n",
        "\n",
        "    if allowed_max_length is not None:\n",
        "      inputs = inputs[:allowed_max_length]\n",
        "      targets = targets[:allowed_max_length]\n",
        "\n",
        "    inputs_lst.append(inputs)\n",
        "    targets_lst.append(targets)\n",
        "\n",
        "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "  targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "  return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "oTbuC1mYtq_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX1998jatx9F",
        "outputId": "bc345c9b-ff2c-4b0f-9da9-5938c0a23d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_1 = torch.tensor(\n",
        "[[-1.0, 1.0],# predictions for 1st token\n",
        "[-0.5, 1.5]]# predictions for 2nd token\n",
        ")\n",
        "targets_1 = torch.tensor([0, 1]) # Correct token indices to generate\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFz7He1yujjo",
        "outputId": "13ced7b9-bc10-4672-fd49-2c3262cbeea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_2 = torch.tensor(\n",
        "[[-1.0, 1.0],\n",
        "[-0.5, 1.5],\n",
        "[-0.5, 1.5]]\n",
        "#A\n",
        ")\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yKoEWHjulwl",
        "outputId": "c61a2989-247e-4378-df0c-fa3e04519f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)\n",
        "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsqixFysurnt",
        "outputId": "b5423fbe-8daa-4449-9e73-4151823f244c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n",
            "loss_1 == loss_3: tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIFGTMCpu4qd",
        "outputId": "5b18568c-2a02-4f6f-c89b-e94d434181d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "train_dataset,\n",
        "batch_size=batch_size,\n",
        "collate_fn=custom_collate_fn,\n",
        "shuffle=True,\n",
        "drop_last=True,\n",
        "num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "val_dataset,\n",
        "batch_size=batch_size,\n",
        "collate_fn=custom_collate_fn,\n",
        "shuffle=False,\n",
        "drop_last=False,\n",
        "num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "test_dataset,\n",
        "batch_size=batch_size,\n",
        "collate_fn=custom_collate_fn,\n",
        "shuffle=False,\n",
        "drop_last=False,\n",
        "num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "PlnvECXrDeTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "  print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO83l_CBDyKB",
        "outputId": "7ed018f1-5be8-4ab6-8466-8b80bae3513a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "\"vocab_size\": 50257,# Vocabulary size\n",
        "\"context_length\": 1024,# Context length\n",
        "\"drop_rate\": 0.0,# Dropout rate\n",
        "\"qkv_bias\": True# Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pui70yRDEAny",
        "outputId": "5509f0da-789b-4737-8423-6bdd5b0e8ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 1024)\n",
              "  (pos_emb): Embedding(1024, 1024)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (12): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (13): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (14): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (15): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (16): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (17): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (18): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (19): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (20): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (21): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (22): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (23): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8o6IWQDGbnk",
        "outputId": "3905e1b6-581d-4269-d15e-2dc225020333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = generate(\n",
        "model=model,\n",
        "idx=text_to_token_ids(input_text, tokenizer),\n",
        "max_new_tokens=35,\n",
        "context_size=BASE_CONFIG[\"context_length\"],\n",
        "eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ],
      "metadata": {
        "id": "q4vDtSAxGfoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvHmuOXWHlt-",
        "outputId": "811e870a-7c67-400a-9a24-48dc2b635475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert the passive to active sentence: 'I was helping my mother open her oven at the end of a 3 day hot summer weekend.'\n",
            "\n",
            "Procedure:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "  val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbdDwGWCJI3G",
        "outputId": "d21f0976-aac8-4bd4-edd2-da0d6031653f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.8258956909179687\n",
            "Validation loss: 3.7619205951690673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "num_epochs = 2\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "model, train_loader, val_loader, optimizer, device,\n",
        "num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "id": "5p4P54n-JoeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDzOwmutKk7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}